<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Productivity on Lalit Maganti</title><link>https://lalitm.com/tags/productivity/</link><description>Recent content in Productivity on Lalit Maganti</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 14 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://lalitm.com/tags/productivity/index.xml" rel="self" type="application/rss+xml"/><item><title>Harnessing Frustration: Using LLMs to Overcome Activation Energy</title><link>https://lalitm.com/llm-motivation-via-emotions/</link><pubDate>Mon, 14 Jul 2025 00:00:00 +0000</pubDate><guid>https://lalitm.com/llm-motivation-via-emotions/</guid><description>&lt;p&gt;One of my biggest weaknesses as a software engineer is procrastination when
facing a new project. When the scope is unclear, I have a tendency to wait until
I feel I&amp;rsquo;ve &amp;ldquo;felt out&amp;rdquo; the problem to start doing anything. I know I&amp;rsquo;ll feel
better and work much faster when I get &amp;ldquo;stuck in&amp;rdquo; but I still struggle with that
first step, overcoming the &amp;ldquo;activation energy&amp;rdquo; required to engage with the
details.&lt;/p&gt;
&lt;p&gt;LLMs have been a game-changer for me in this respect: I can just throw a couple
of sentences at them with the shape of the problem. This leads to one of two
outcomes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The LLM comes up with a good solution, usually in a slightly different way
than what I was thinking. I realize &amp;ldquo;oh wow the solution is much simpler than
I thought&amp;rdquo;. Straight away I start thinking about the consequences of
implementing and improving what the LLM suggested.&lt;/li&gt;
&lt;li&gt;The LLM comes up with a solution that I intuitively recognize as &amp;ldquo;wrong&amp;rdquo;. My
immediate reaction is frustration (&amp;ldquo;How could it get it so wrong&amp;rdquo;) which
leads me to go back and forth with the model, explaining to it why its
solution could not &lt;em&gt;possibly&lt;/em&gt; work. But in the process of arguing with the
model, my brain is churning away and generating variations or different
approaches that &lt;em&gt;could&lt;/em&gt; work. After a while, even if the AI is still on the
wrong track, the debate will trigger a moment of inspiration where suddenly
the solution will come to me. I&amp;rsquo;ll excitedly start up a new conversation and
start working through it with the model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The key is the emotional reaction I have immediately to the LLM&amp;rsquo;s response,
either &lt;strong&gt;excitement or frustration&lt;/strong&gt;. By harnessing this immediate feedback
loop, I get my brain out of its passive, procrastination mode. It&amp;rsquo;s almost like
a jolt: either I&amp;rsquo;m thrilled because it&amp;rsquo;s simpler than I thought, or I&amp;rsquo;m spurred
to action by the urge to correct a perceived &amp;lsquo;wrong&amp;rsquo; answer. This forces me to
engage with the problem in a meaningful way.&lt;/p&gt;</description></item></channel></rss>